Configuration with ZConfig
==========================

ZRS supports configuration using
ZConfig.  ZRS provides a zrs directive to create storages that can
replicate from other storages and that can be replicated from. To
use these, you have to import zc.zrs:

    >>> import os, time, ZODB.config, shutil
    >>> primary = ZODB.config.storageFromString("""
    ...   %import zc.zrs
    ...
    ...   <zrs>
    ...      replicate-to ./primary.sock
    ...      <filestorage>
    ...          path primary.fs
    ...          blob-dir primary-blobs
    ...      </filestorage>
    ...   </zrs>
    ... """)
    >>> time.sleep(.01) # Wait for server to start

In this example, we created a primary storage that listens on a
unix-domain socket. Normally, we'd use a TCP address instead, but we
used a unix-domain socket to avoid having to pick an unused port. :)

The primary storage wraps a file storage.

    >>> primary
    <zc.zrs.primary.Primary instance at 0x2aaaab0c53f8>

    >>> os.path.exists('primary.sock')
    True
    >>> os.path.exists('primary.fs')
    True


Defining a secondary storage is similar:

    >>> secondary = ZODB.config.storageFromString("""
    ...   %import zc.zrs
    ...
    ...   <zrs>
    ...      replicate-from ./primary.sock
    ...      <filestorage>
    ...          path secondary.fs
    ...          blob-dir secondary-blobs
    ...      </filestorage>
    ...   </zrs>
    ... """)
    >>> time.sleep(.01) # Wait for server to start

    >>> secondary
    <zc.zrs.secondary.Secondary instance at 0x2aaaab0e8d40>

    >>> os.path.exists('secondary.fs')
    True

   There're keep-alive and check-checksum options that default to 0
   and False:

    >>> secondary._factory.keep_alive_delay
    0

    >>> secondary._factory.check_checksums
    False

We can combine a primary and a secondary by providing both
replicate-from and replicate-to:

    >>> secondary.close()
    >>> time.sleep(.01) # Wait for close (in separate thread)
    >>> os.remove('secondary.fs')
    >>> shutil.rmtree('secondary-blobs')

    >>> secondary = ZODB.config.storageFromString("""
    ...   %import zc.zrs
    ...
    ...   <zrs>
    ...      replicate-from ./primary.sock
    ...      replicate-to ./secondary.sock
    ...      keep-alive-delay 60
    ...      check-checksums true
    ...      <filestorage>
    ...         path secondary.fs
    ...         blob-dir secondary-blobs
    ...      </filestorage>
    ...   </zrs>
    ... """)
    >>> time.sleep(.01) # Wait for server to start

    >>> secondary
    <zc.zrs.secondary.Secondary instance at 0x2aaaab0f5680>

    >>> os.path.exists('secondary.fs')
    True
    >>> os.path.exists('secondary.sock')
    True

    >>> secondary._factory.keep_alive_delay
    60

    >>> secondary._factory.check_checksums
    True

Let's create a secondary secondary and commit some data to the primary storage.

    >>> secondary2 = ZODB.config.storageFromString("""
    ...   %import zc.zrs
    ...
    ...   <zrs>
    ...      replicate-from ./secondary.sock
    ...      <filestorage>
    ...         path secondary2.fs
    ...         blob-dir secondary2-blobs
    ...      </filestorage>
    ...   </zrs>
    ... """)
    >>> time.sleep(.01) # Wait for server to start

    >>> import time, transaction, ZODB, ZODB.blob
    >>> db = ZODB.DB(primary)
    >>> conn = db.open()
    >>> conn.root()[1] = conn.root().__class__()
    >>> conn.root()[2] = ZODB.blob.Blob()
    >>> conn.root()[2].open('w').write("some blob data")
    >>> transaction.commit()

    >>> conn.root()
    {1: {}, 2: <ZODB.blob.Blob object at 0xb6463cec>}

.. wait a little while to replicate

    >>> time.sleep(1)

Now, we see that we have the data replicated to our secondary
secondary:

    >>> db2 = ZODB.DB(secondary2)
    >>> conn2 = db2.open()
    >>> conn2.root()
    {1: {}, 2: <ZODB.blob.Blob object at 0xb63c8c6c>}

    >>> conn.root()[2].open().read()
    'some blob data'

    >>> os.path.getsize('primary.fs') == os.path.getsize('secondary2.fs')
    True

Replication Logs
================

Replication logs are configured as ZODB storages using a
replicationlog section:

    >>> os.mkdir('log')
    >>> log = ZODB.config.storageFromString("""
    ...   %import zc.zrs
    ...
    ...   <replicationlog>
    ...      replicate-from ./secondary.sock
    ...      destination log
    ...      file-size 1000
    ...      keep-alive-delay 60
    ...      check-checksums true
    ...   </replicationlog>
    ... """)

    >>> log._storage.max_size
    1000

    >>> log._factory.keep_alive_delay
    60
    >>> log._factory.check_checksums
    True

    >>> for i in range(3, 6):
    ...    conn.root()[i] = ZODB.blob.Blob()
    ...    conn.root()[2].open('w').write("x"*1000)
    ...    transaction.commit()

.. wait for replication

    >>> time.sleep(1)

If we look at the log directory, we can see the log files that were created:

    >>> for name in sorted(os.listdir('log')):
    ...     print name, os.stat(os.path.join('log', name)).st_size
    0000000000000000 1989
    036c6b90f3333335 1401
    036c6b90f3333336 1420
    036c6b90f3333337 0

The log recorders don't provide most storage methods, howver, they do
provide lastTransaction and getSize:

    >>> log.lastTransaction() == primary.lastTransaction()
    True

    >>> log.getSize()
    4810

The file-size, keep-alive-delay and check-checksums options are
optional:

    >>> os.mkdir('log2')
    >>> log2 = ZODB.config.storageFromString("""
    ...   %import zc.zrs
    ...
    ...   <replicationlog>
    ...      replicate-from ./secondary.sock
    ...      destination log2
    ...   </replicationlog>
    ... """)

    >>> log2._storage.max_size
    524288000

    >>> log2._factory.keep_alive_delay
    0

    >>> log2._factory.check_checksums
    False

.. wait for replication

    >>> time.sleep(1)

If we look at the log directory, we see we get only one log file,
because the default size is much larger than what we specifiled before:

    >>> for name in sorted(os.listdir('log2')):
    ...     print name, os.stat(os.path.join('log2', name)).st_size
    0000000000000000 4810

.. cleanup

   >>> log.close()
   >>> log2.close()
   >>> db2.close()
   >>> secondary.close()
   >>> db.close()
